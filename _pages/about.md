---
permalink: /
title: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am currently a first-year Master's student at [Sichuan University](https://www.scu.edu.cn/), under the supervision of [Prof. Honggang Chen](https://sites.google.com/view/honggangchen/). Previously, I had the honor of visiting the [Visual Intelligence & Perception Lab (VIP Lab)](https://zhengfenglab.com/) at [SUSTech](https://www.sustech.edu.cn/en/), led by [Prof. Feng Zheng](https://faculty.sustech.edu.cn/?tagid=fengzheng&go=1&iscss=1&snapid=1&lang=en), and also gained valuable experience at the [Machine Intelligence Laboratory (MiLAB)](https://milab.westlake.edu.cn/) at [Westlake University](https://www.westlake.edu.cn/), guided by [Siteng Huang](https://kyonhuang.top/).

## Research interests

My current research interests can be summarized as follows:
* **Vision-language Learning**: visual grounding and [referring video object segmentation](https://github.com/gaomingqi/Awesome-Video-Object-Segmentation).
* **Transfer Learning**: [parameter-efficient transfer learning](https://github.com/synbol/Awesome-Parameter-Efficient-Transfer-Learning) and zero-shot learning.
* **Generative Models**: text-to-image generaction and text-to-video generaction.

Please feel free to reach out to me at [this email](liuxuyang@stu.scu.edu.cn), if you are interested in collaborating with me.

## News

* **[April 9, 2024]**: Our [paper]() is selected as **Oral Presentation** in ICME 2024! Congratulations to all collaborators!
* **[March 13, 2024]**: One co-first author [paper]() about parameter-efficient tuning for visual grounding got accepted by ICME 2024!
* **[December 13, 2023]**: One first author [paper](https://arxiv.org/abs/2309.01141) about diffusion-based zero-shot visual grounding got accepted by ICASSP 2024!


## Publications

### **DARA: Domain- and Relation-aware Adapters Make Parameter-efficient Tuning for Visual Grounding**

- Ting Liu†, **Xuyang Liu†**, Siteng Huang, Honggang Chen, Quanjun Yin, Long Qin, Donglin Wang, Yue Hu
- *IEEE International Conference on Multimedia & Expo (ICME)*, 2024 (**Oral Presentation**)
- [[Paper]()]
[[code](https://github.com/liuting20/DARA)]

### **VGDiffZero: Text-to-image Diffusion Models Can Be Zero-shot Visual Grounders**

- **Xuyang Liu**, Siteng Huang, Yachen Kang, Honggang Chen, Donglin Wang
- *IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)*, 2024
- [[paper](https://arxiv.org/pdf/2309.01141.pdf)]
[[code](https://github.com/xuyang-liu16/VGDiffZero)]
[[poster](/files/ICASSP-2024-VGDiffZero-Poster.pdf)]

### **GLMLP-TRANS: A transportation mode detection model using lightweight sensors integrated in smartphones**

- **Xuyang Liu**
- *Computer Communications*, 2022 (**SCI Q1**)
- [[paper](https://www.sciencedirect.com/science/article/abs/pii/S0140366422002535)]
[[code](https://github.com/xuyang-liu16/GLMLP-TRANS)]

## Services

### Conference Reviewer
* ACM International Conference on Multimedia [(MM)](https://2024.acmmm.org/)
* ACM International Conference on Multimedia Retrieval [(ICMR)](http://icmr2024.org/)

